{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Feature Importance for 1991 Dataset:\n",
      "DepDelay: 24.10%\n",
      "ActualElapsedTime: 16.75%\n",
      "Distance: 15.85%\n",
      "DepTime: 8.50%\n",
      "Origin: 7.65%\n",
      "Dest: 6.50%\n",
      "FlightNum: 6.27%\n",
      "Month: 5.81%\n",
      "UniqueCarrier: 3.83%\n",
      "DayofMonth: 3.02%\n",
      "DayOfWeek: 1.72%\n",
      "Cancelled: 0.00%\n",
      "Diverted: 0.00%\n",
      "\n",
      "Decision Tree Feature Importance for 2001 Dataset:\n",
      "DepDelay: 35.04%\n",
      "TaxiOut: 11.09%\n",
      "Distance: 9.61%\n",
      "ActualElapsedTime: 8.39%\n",
      "DepTime: 5.59%\n",
      "Origin: 4.88%\n",
      "FlightNum: 4.69%\n",
      "TaxiIn: 3.75%\n",
      "Dest: 3.69%\n",
      "AirTime: 3.44%\n",
      "Month: 3.31%\n",
      "DayofMonth: 2.86%\n",
      "UniqueCarrier: 2.05%\n",
      "DayOfWeek: 1.62%\n",
      "Cancelled: 0.00%\n",
      "Diverted: 0.00%\n",
      "\n",
      "XGBoost Feature Importance for 1991 Dataset:\n",
      "DepDelay: 54.37%\n",
      "Distance: 10.80%\n",
      "ActualElapsedTime: 9.65%\n",
      "Origin: 5.86%\n",
      "DayOfWeek: 4.76%\n",
      "UniqueCarrier: 4.55%\n",
      "Dest: 3.66%\n",
      "Month: 2.49%\n",
      "DepTime: 1.78%\n",
      "FlightNum: 1.61%\n",
      "DayofMonth: 0.47%\n",
      "Cancelled: 0.00%\n",
      "Diverted: 0.00%\n",
      "\n",
      "XGBoost Feature Importance for 2001 Dataset:\n",
      "DepDelay: 47.77%\n",
      "TaxiOut: 18.29%\n",
      "TaxiIn: 9.58%\n",
      "Distance: 3.95%\n",
      "AirTime: 3.83%\n",
      "ActualElapsedTime: 3.59%\n",
      "Origin: 2.90%\n",
      "UniqueCarrier: 2.70%\n",
      "Dest: 1.81%\n",
      "FlightNum: 1.66%\n",
      "DayOfWeek: 1.65%\n",
      "DepTime: 1.18%\n",
      "Month: 0.97%\n",
      "DayofMonth: 0.13%\n",
      "Cancelled: 0.00%\n",
      "Diverted: 0.00%\n",
      "\n",
      "Decision Tree Accuracy for 1991 Dataset: 90.38%\n",
      "Decision Tree Accuracy for 2001 Dataset: 86.34%\n",
      "\n",
      "XGBoost Accuracy for 1991 Dataset: 86.74%\n",
      "XGBoost Accuracy for 2001 Dataset: 89.18%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load datasets\n",
    "df_1991 = pd.read_csv('1991_cleaned.csv.gz')\n",
    "df_2001 = pd.read_csv('2001_cleaned.csv.gz')\n",
    "\n",
    "# Create the 'DELAYED' column\n",
    "df_1991['DELAYED'] = (df_1991['ArrDelay'] > 0).astype(int)\n",
    "df_2001['DELAYED'] = (df_2001['ArrDelay'] > 0).astype(int)\n",
    "\n",
    "# Drop the 'ArrDelay' column\n",
    "df_1991 = df_1991.drop('ArrDelay', axis=1)\n",
    "df_2001 = df_2001.drop('ArrDelay', axis=1)\n",
    "\n",
    "# Define numerical and categorical columns for each dataset\n",
    "num_cols_1991 = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'FlightNum',\n",
    "                 'ActualElapsedTime', 'DepDelay', 'Distance',\n",
    "                 'Cancelled', 'Diverted']\n",
    "num_cols_2001 = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'FlightNum',\n",
    "                 'ActualElapsedTime', 'AirTime', 'DepDelay', 'Distance',\n",
    "                 'TaxiIn', 'TaxiOut', 'Cancelled', 'Diverted']\n",
    "cat_cols_1991 = [\"UniqueCarrier\", \"Origin\", \"Dest\"]\n",
    "cat_cols_2001 = [\"UniqueCarrier\", \"Origin\", \"Dest\"]\n",
    "\n",
    "# Separate the target variable\n",
    "target_variable = ['DELAYED']\n",
    "\n",
    "# Store a copy of the target variable separately\n",
    "df_1991_target = df_1991[target_variable].copy()\n",
    "df_2001_target = df_2001[target_variable].copy()\n",
    "\n",
    "# Drop the target variable for feature scaling\n",
    "df_1991_features = df_1991.drop(target_variable, axis=1)\n",
    "df_2001_features = df_2001.drop(target_variable, axis=1)\n",
    "\n",
    "# Apply label encoding to categorical variables using factorize\n",
    "for col in cat_cols_1991:\n",
    "    df_1991_features[col], _ = pd.factorize(df_1991_features[col])\n",
    "\n",
    "for col in cat_cols_2001:\n",
    "    df_2001_features[col], _ = pd.factorize(df_2001_features[col])\n",
    "\n",
    "# Concatenate numerical and categorical columns\n",
    "df_1991_combined = pd.concat([df_1991_features[num_cols_1991], df_1991_features[cat_cols_1991]], axis=1)\n",
    "df_2001_combined = pd.concat([df_2001_features[num_cols_2001], df_2001_features[cat_cols_2001]], axis=1)\n",
    "\n",
    "# Standardize combined numerical and categorical variables using the mean and standard deviation of each dataset\n",
    "scaler_1991 = StandardScaler()\n",
    "scaler_2001 = StandardScaler()\n",
    "\n",
    "df_1991_scaled = scaler_1991.fit_transform(df_1991_combined)\n",
    "df_1991_scaled = pd.DataFrame(df_1991_scaled, columns=df_1991_combined.columns)\n",
    "df_1991_scaled['DELAYED'] = df_1991_target.reset_index(drop=True)  # Reset index\n",
    "\n",
    "df_2001_scaled = scaler_2001.fit_transform(df_2001_combined)\n",
    "df_2001_scaled = pd.DataFrame(df_2001_scaled, columns=df_2001_combined.columns)\n",
    "df_2001_scaled['DELAYED'] = df_2001_target.reset_index(drop=True)  # Reset index\n",
    "\n",
    "os.makedirs(\"engineering\", exist_ok=True)\n",
    "pd.DataFrame(df_1991_scaled.sample(50)).to_csv('engineering/engineering_1991.csv', index=False)\n",
    "pd.DataFrame(df_2001_scaled.sample(50)).to_csv('engineering/engineering_2001.csv', index=False)\n",
    "\n",
    "# Split the 1991 dataset into training, testing, and validation sets\n",
    "train_data_1991, test_data_1991 = train_test_split(df_1991_scaled, test_size=0.2, random_state=42)\n",
    "train_data_1991, val_data_1991 = train_test_split(train_data_1991, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the 2001 dataset into training, testing, and validation sets\n",
    "train_data_2001, test_data_2001 = train_test_split(df_2001_scaled, test_size=0.2, random_state=42)\n",
    "train_data_2001, val_data_2001 = train_test_split(train_data_2001, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define features and target for each dataset\n",
    "X_train_1991 = train_data_1991[num_cols_1991 + cat_cols_1991]\n",
    "y_train_1991 = train_data_1991['DELAYED']\n",
    "X_val_1991 = val_data_1991[num_cols_1991 + cat_cols_1991]\n",
    "y_val_1991 = val_data_1991['DELAYED']\n",
    "X_test_1991 = test_data_1991[num_cols_1991 + cat_cols_1991]\n",
    "y_test_1991 = test_data_1991['DELAYED']\n",
    "\n",
    "X_train_2001 = train_data_2001[num_cols_2001 + cat_cols_2001]\n",
    "y_train_2001 = train_data_2001['DELAYED']\n",
    "X_val_2001 = val_data_2001[num_cols_2001 + cat_cols_2001]\n",
    "y_val_2001 = val_data_2001['DELAYED']\n",
    "X_test_2001 = test_data_2001[num_cols_2001 + cat_cols_2001]\n",
    "y_test_2001 = test_data_2001['DELAYED']\n",
    "\n",
    "# Create folders if they do not exist\n",
    "folders = ['models', 'feature_importance', 'accuracies']\n",
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Function to extract feature importance from tree-based models\n",
    "def get_tree_feature_importance(model, feature_names):\n",
    "    return dict(zip(feature_names, model.feature_importances_))\n",
    "\n",
    "# Define the Decision Tree model\n",
    "dt_model_1991 = DecisionTreeClassifier(random_state=42)\n",
    "dt_model_2001 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the Decision Tree model to the 1991 dataset\n",
    "dt_model_1991.fit(X_train_1991, y_train_1991)\n",
    "\n",
    "# Fit the Decision Tree model to the 2001 dataset\n",
    "dt_model_2001.fit(X_train_2001, y_train_2001)\n",
    "\n",
    "# Extract feature importance for Decision Tree model (1991 dataset)\n",
    "feature_importance_dt_1991 = get_tree_feature_importance(dt_model_1991, num_cols_1991 + cat_cols_1991)\n",
    "\n",
    "# Extract feature importance for Decision Tree model (2001 dataset)\n",
    "feature_importance_dt_2001 = get_tree_feature_importance(dt_model_2001, num_cols_2001 + cat_cols_2001)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model_1991 = XGBClassifier(random_state=42)\n",
    "xgb_model_2001 = XGBClassifier(random_state=42)\n",
    "\n",
    "# Fit the XGBoost model to the 1991 dataset\n",
    "xgb_model_1991.fit(X_train_1991, y_train_1991)\n",
    "\n",
    "# Fit the XGBoost model to the 2001 dataset\n",
    "xgb_model_2001.fit(X_train_2001, y_train_2001)\n",
    "\n",
    "# Extract feature importance for XGBoost model (1991 dataset)\n",
    "feature_importance_xgb_1991 = get_tree_feature_importance(xgb_model_1991, num_cols_1991 + cat_cols_1991)\n",
    "\n",
    "# Extract feature importance for XGBoost model (2001 dataset)\n",
    "feature_importance_xgb_2001 = get_tree_feature_importance(xgb_model_2001, num_cols_2001 + cat_cols_2001)\n",
    "\n",
    "# Print feature importance for Decision Tree model (1991 dataset)\n",
    "print(\"\\nDecision Tree Feature Importance for 1991 Dataset:\")\n",
    "for feature, importance in sorted(feature_importance_dt_1991.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance*100:.2f}%\")\n",
    "\n",
    "# Print feature importance for Decision Tree model (2001 dataset)\n",
    "print(\"\\nDecision Tree Feature Importance for 2001 Dataset:\")\n",
    "for feature, importance in sorted(feature_importance_dt_2001.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance*100:.2f}%\")\n",
    "\n",
    "# Print feature importance for XGBoost model (1991 dataset)\n",
    "print(\"\\nXGBoost Feature Importance for 1991 Dataset:\")\n",
    "for feature, importance in sorted(feature_importance_xgb_1991.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance*100:.2f}%\")\n",
    "\n",
    "# Print feature importance for XGBoost model (2001 dataset)\n",
    "print(\"\\nXGBoost Feature Importance for 2001 Dataset:\")\n",
    "for feature, importance in sorted(feature_importance_xgb_2001.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {importance*100:.2f}%\")\n",
    "\n",
    "# Save Decision Tree models\n",
    "joblib.dump(dt_model_1991, 'models/DT_1991_model.joblib')\n",
    "joblib.dump(dt_model_2001, 'models/DT_2001_model.joblib')\n",
    "\n",
    "# Save XGBoost models\n",
    "joblib.dump(xgb_model_1991, 'models/XGB_1991_model.joblib')\n",
    "joblib.dump(xgb_model_2001, 'models/XGB_2001_model.joblib')\n",
    "\n",
    "# Save feature importance as CSV\n",
    "feature_importance_dt_xgb_1991 = {'Feature': [], 'DT_Importance': [], 'XGB_Importance': []}\n",
    "feature_importance_dt_xgb_2001 = {'Feature': [], 'DT_Importance': [], 'XGB_Importance': []}\n",
    "\n",
    "for feature in num_cols_1991 + cat_cols_1991:\n",
    "    feature_importance_dt_xgb_1991['Feature'].append(feature)\n",
    "    feature_importance_dt_xgb_1991['DT_Importance'].append(feature_importance_dt_1991.get(feature, 0))\n",
    "    feature_importance_dt_xgb_1991['XGB_Importance'].append(feature_importance_xgb_1991.get(feature, 0))\n",
    "\n",
    "for feature in num_cols_2001 + cat_cols_2001:\n",
    "    feature_importance_dt_xgb_2001['Feature'].append(feature)\n",
    "    feature_importance_dt_xgb_2001['DT_Importance'].append(feature_importance_dt_2001.get(feature, 0))\n",
    "    feature_importance_dt_xgb_2001['XGB_Importance'].append(feature_importance_xgb_2001.get(feature, 0))\n",
    "\n",
    "df_feature_importance_1991 = pd.DataFrame(feature_importance_dt_xgb_1991)\n",
    "df_feature_importance_2001 = pd.DataFrame(feature_importance_dt_xgb_2001)\n",
    "\n",
    "df_feature_importance_1991.to_csv('feature_importance/feature_importance_1991.csv', index=False)\n",
    "df_feature_importance_2001.to_csv('feature_importance/feature_importance_2001.csv', index=False)\n",
    "\n",
    "predictions_dt_1991 = dt_model_1991.predict(X_test_1991)\n",
    "accuracy_dt_1991 = accuracy_score(y_test_1991, predictions_dt_1991)\n",
    "print(f\"\\nDecision Tree Accuracy for 1991 Dataset: {accuracy_dt_1991*100:.2f}%\")\n",
    "\n",
    "# Make predictions and evaluate for Decision Tree (2001 dataset)\n",
    "predictions_dt_2001 = dt_model_2001.predict(X_test_2001)\n",
    "accuracy_dt_2001 = accuracy_score(y_test_2001, predictions_dt_2001)\n",
    "print(f\"Decision Tree Accuracy for 2001 Dataset: {accuracy_dt_2001*100:.2f}%\")\n",
    "\n",
    "# Make predictions and evaluate for XGBoost (1991 dataset)\n",
    "predictions_xgb_1991 = xgb_model_1991.predict(X_test_1991)\n",
    "accuracy_xgb_1991 = accuracy_score(y_test_1991, predictions_xgb_1991)\n",
    "print(f\"\\nXGBoost Accuracy for 1991 Dataset: {accuracy_xgb_1991*100:.2f}%\")\n",
    "\n",
    "# Make predictions and evaluate for XGBoost (2001 dataset)\n",
    "predictions_xgb_2001 = xgb_model_2001.predict(X_test_2001)\n",
    "accuracy_xgb_2001 = accuracy_score(y_test_2001, predictions_xgb_2001)\n",
    "print(f\"XGBoost Accuracy for 2001 Dataset: {accuracy_xgb_2001*100:.2f}%\")\n",
    "\n",
    "# Save accuracies as CSV\n",
    "df_accuracies = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'XGBoost'],\n",
    "    '1991 Accuracy': [accuracy_dt_1991, accuracy_xgb_1991],\n",
    "    '2001 Accuracy': [accuracy_dt_2001, accuracy_xgb_2001]\n",
    "})\n",
    "\n",
    "df_accuracies.to_csv('accuracies/accuracies.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
